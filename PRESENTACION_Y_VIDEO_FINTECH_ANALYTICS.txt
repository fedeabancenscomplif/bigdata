================================================================================
                    ğŸš€ FINTECH ANALYTICS - ANÃLISIS DE ONBOARDING Y A/B TESTING
                    ================================================================
                    PROYECTO DE BIG DATA ENGINEERING
                    ================================================================

================================================================================
                                    PRESENTACIÃ“N
================================================================================

ğŸ“‹ AGENDA
---------
1. Contexto del Negocio
2. Arquitectura de la SoluciÃ³n
3. TecnologÃ­as Utilizadas
4. Proceso de Desarrollo
5. Pre-procesamiento y TransformaciÃ³n
6. Decisiones TÃ©cnicas
7. Resultados y MÃ©tricas
8. Conclusiones y PrÃ³ximos Pasos

================================================================================
1. CONTEXTO DEL NEGOCIO
================================================================================

ğŸ¦ PROBLEMA IDENTIFICADO
â€¢ PÃ©rdida de usuarios durante el proceso de onboarding
â€¢ Falta de visibilidad en el comportamiento de usuarios
â€¢ Necesidad de optimizaciÃ³n de la experiencia de usuario
â€¢ ImplementaciÃ³n de A/B testing para validar mejoras

ğŸ¯ OBJETIVOS DEL PROYECTO
â€¢ Reducir la tasa de abandono en onboarding
â€¢ Analizar el funnel de activaciÃ³n de usuarios
â€¢ Implementar A/B testing para validar mejoras
â€¢ Crear dashboard en tiempo real para monitoreo
â€¢ Optimizar la experiencia del usuario

ğŸ“Š MÃ‰TRICAS CLAVE (KPIs)
â€¢ Drop Rate: Usuarios que abandonan el proceso
â€¢ Activation Rate: Usuarios que completan activaciÃ³n
â€¢ Setup Rate: Usuarios que configuran su cuenta
â€¢ Habit Rate: Usuarios que desarrollan hÃ¡bito de uso

================================================================================
2. ARQUITECTURA DE LA SOLUCIÃ“N
================================================================================

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Datasets CSV  â”‚    â”‚   Apache Spark  â”‚    â”‚  Apache Cassandraâ”‚
â”‚                 â”‚    â”‚   (PySpark)     â”‚    â”‚                 â”‚
â”‚ â€¢ lk_onboarding â”‚â”€â”€â”€â–¶â”‚   ETL Pipeline  â”‚â”€â”€â”€â–¶â”‚   Base de Datos â”‚
â”‚ â€¢ dim_users     â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ transactions  â”‚    â”‚ â€¢ Limpieza      â”‚    â”‚ â€¢ MÃ©tricas      â”‚
â”‚                 â”‚    â”‚ â€¢ TransformaciÃ³nâ”‚    â”‚ â€¢ A/B Testing   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ â€¢ Carga         â”‚    â”‚ â€¢ Tiempo Real   â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
                                                       â–¼
                                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                              â”‚   Streamlit     â”‚
                                              â”‚   Dashboard     â”‚
                                              â”‚                 â”‚
                                              â”‚ â€¢ VisualizaciÃ³n â”‚
                                              â”‚ â€¢ AnÃ¡lisis      â”‚
                                              â”‚ â€¢ Tiempo Real   â”‚
                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

FLUJO DE DATOS:
1. Ingesta: Datasets CSV â†’ Apache Spark
2. Procesamiento: ETL con PySpark â†’ TransformaciÃ³n y cÃ¡lculo de mÃ©tricas
3. Almacenamiento: Resultados â†’ Apache Cassandra
4. VisualizaciÃ³n: Dashboard Streamlit â†’ Consume datos directamente desde Cassandra

================================================================================
3. TECNOLOGÃAS UTILIZADAS
================================================================================

ğŸ› ï¸ PROCESAMIENTO DE DATOS
â€¢ Apache Spark 3.5.0: Procesamiento distribuido y ETL
â€¢ PySpark: API de Python para Spark
â€¢ Pandas 2.1.4: ManipulaciÃ³n de datos

ğŸ—„ï¸ BASE DE DATOS
â€¢ Apache Cassandra: Base de datos NoSQL para tiempo real
â€¢ Cassandra Driver 3.28.0: Conector Python

ğŸ“Š DASHBOARD Y VISUALIZACIÃ“N
â€¢ Streamlit 1.28.1: Framework para dashboards web
â€¢ Plotly 5.17.0: Visualizaciones interactivas
â€¢ Matplotlib 3.8.2: Visualizaciones bÃ¡sicas
â€¢ Seaborn 0.13.0: Visualizaciones estadÃ­sticas

ğŸ—ï¸ INFRAESTRUCTURA
â€¢ Docker: ContainerizaciÃ³n de servicios
â€¢ Docker Compose: OrquestaciÃ³n de contenedores

================================================================================
4. PROCESO DE DESARROLLO
================================================================================

ğŸ”§ FASE 1: ANÃLISIS EXPLORATORIO
âœ… ExploraciÃ³n de datasets: IdentificaciÃ³n de estructura y calidad
âœ… DetecciÃ³n de inconsistencias: Valores faltantes y duplicados
âœ… ValidaciÃ³n de datos: VerificaciÃ³n de integridad
âœ… DocumentaciÃ³n de hallazgos: Reporte de calidad de datos

ğŸ”§ FASE 2: DISEÃ‘O DE ARQUITECTURA
âœ… SelecciÃ³n de tecnologÃ­as: Spark + Cassandra + Streamlit
âœ… DiseÃ±o del pipeline: ETL optimizado
âœ… DefiniciÃ³n de mÃ©tricas: KPIs de negocio
âœ… PlanificaciÃ³n de A/B testing: DistribuciÃ³n 5%/95%

ğŸ”§ FASE 3: DESARROLLO DEL ETL
âœ… ImplementaciÃ³n del pipeline: CÃ³digo PySpark
âœ… Limpieza de datos: Filtrado y validaciÃ³n
âœ… CÃ¡lculo de mÃ©tricas: LÃ³gicas de negocio
âœ… IntegraciÃ³n con Cassandra: Almacenamiento optimizado

ğŸ”§ FASE 4: DESARROLLO DEL DASHBOARD
âœ… Interfaz de usuario: Streamlit responsive
âœ… Visualizaciones: GrÃ¡ficos interactivos
âœ… ConexiÃ³n en tiempo real: Cassandra directa
âœ… Funcionalidades avanzadas: Filtros y exportaciÃ³n

================================================================================
5. PRE-PROCESAMIENTO Y TRANSFORMACIÃ“N
================================================================================

ğŸ§¹ LIMPIEZA DE DATOS
â€¢ Filtrado por segmento: Solo usuarios con segmento vÃ¡lido (1 o 2)
â€¢ ResoluciÃ³n de inconsistencias: Segmentos duplicados por usuario
â€¢ Formateo de fechas: ConversiÃ³n a formato estÃ¡ndar
â€¢ ValidaciÃ³n de integridad: VerificaciÃ³n de relaciones entre tablas

ğŸ”„ TRANSFORMACIÃ“N DE DATOS
â€¢ CÃ¡lculo de Drop Rate: drop = 1 si return = 0
â€¢ CÃ¡lculo de Activation Rate: Basado en existencia de activacion_dt
â€¢ CÃ¡lculo de Setup Rate: Basado en existencia de setup_dt
â€¢ CÃ¡lculo de Habit Rate: Diferenciado por segmento
  - Individuals: â‰¥5 dÃ­as distintos de transacciones en 30 dÃ­as
  - Sellers: â‰¥5 cobros (tipos 8 o 9) en 30 dÃ­as

ğŸ”¬ A/B TESTING
â€¢ AsignaciÃ³n aleatoria: DistribuciÃ³n 5% control, 95% tratamiento
â€¢ SimulaciÃ³n de experimento: Para validar mejoras futuras
â€¢ MÃ©tricas comparativas: AnÃ¡lisis de diferencias entre grupos

================================================================================
6. DECISIONES TÃ‰CNICAS
================================================================================

âš¡ SELECCIÃ“N DE SPARK
â€¢ Procesamiento distribuido: Manejo de grandes volÃºmenes
â€¢ OptimizaciÃ³n de memoria: Cache inteligente
â€¢ Escalabilidad: Crecimiento futuro del proyecto
â€¢ IntegraciÃ³n con Cassandra: Compatibilidad nativa

ğŸ—„ï¸ SELECCIÃ“N DE CASSANDRA
â€¢ Consultas rÃ¡pidas: Optimizado para lecturas
â€¢ Escalabilidad horizontal: Manejo de grandes volÃºmenes
â€¢ Alta disponibilidad: Tolerancia a fallos
â€¢ Tiempo real: Datos actualizados instantÃ¡neamente

ğŸ“Š SELECCIÃ“N DE STREAMLIT
â€¢ Desarrollo rÃ¡pido: Prototipado Ã¡gil
â€¢ Interfaz intuitiva: FÃ¡cil de usar
â€¢ IntegraciÃ³n Python: Compatibilidad con el stack
â€¢ Deployment simple: FÃ¡cil despliegue

ğŸ—ï¸ ARQUITECTURA DE DATOS
â€¢ LEFT JOINs: Mantener todos los usuarios de onboarding
â€¢ Filtrado inteligente: Solo datos relevantes
â€¢ Cache optimizado: 5 minutos para mejor rendimiento
â€¢ Manejo de errores: Robustez en la conexiÃ³n

================================================================================
7. RESULTADOS Y MÃ‰TRICAS
================================================================================

ğŸ“Š FUNNEL DE ONBOARDING
Usuarios Registrados (100%)
         â†“
    ActivaciÃ³n (~60-80%)
         â†“
      Setup (~40-60%)
         â†“
     HÃ¡bito (~20-40%)

ğŸ‘¥ ANÃLISIS POR SEGMENTO
â€¢ Individuals: Usuarios individuales
â€¢ Sellers: Vendedores/comerciantes
â€¢ Diferencias significativas en tasas de conversiÃ³n

ğŸ”¬ A/B TESTING
â€¢ Grupo Control: 5% de usuarios (baseline)
â€¢ Grupo Treatment: 95% de usuarios (nueva experiencia)
â€¢ MÃ©tricas comparativas: Diferencias estadÃ­sticas

ğŸ“ˆ DASHBOARD EN TIEMPO REAL
â€¢ ConfiguraciÃ³n dinÃ¡mica: Host, puerto, keyspace, tabla
â€¢ Prueba de conexiÃ³n: VerificaciÃ³n automÃ¡tica
â€¢ NavegaciÃ³n modular: 5 secciones principales
â€¢ ExportaciÃ³n de datos: Descarga de datos filtrados

================================================================================
8. CONCLUSIONES Y PRÃ“XIMOS PASOS
================================================================================

ğŸ¯ LOGROS ALCANZADOS
âœ… Pipeline ETL completo: Procesamiento automatizado
âœ… Dashboard en tiempo real: Monitoreo continuo
âœ… A/B testing implementado: ValidaciÃ³n de mejoras
âœ… MÃ©tricas de negocio: KPIs claros y medibles
âœ… Arquitectura escalable: Preparada para crecimiento

ğŸ’° BENEFICIOS DEL NEGOCIO
â€¢ ReducciÃ³n de drop rate: 10-20% esperado
â€¢ Incremento en activation rate: 15-25% esperado
â€¢ Mejora en habit formation: 20-30% esperado
â€¢ Visibilidad completa: Dashboard en tiempo real

ğŸš€ PRÃ“XIMOS PASOS
1. ImplementaciÃ³n en producciÃ³n: Despliegue del pipeline
2. Monitoreo continuo: Seguimiento de mÃ©tricas
3. OptimizaciÃ³n basada en datos: Mejoras iterativas
4. ExpansiÃ³n a otros paÃ­ses: Escalabilidad geogrÃ¡fica
5. Machine Learning: PersonalizaciÃ³n de experiencia

ğŸ“š LECCIONES APRENDIDAS
â€¢ Importancia de la calidad de datos: Filtrado crÃ­tico
â€¢ Valor del tiempo real: Cassandra para dashboards
â€¢ Eficiencia de Spark: Procesamiento distribuido
â€¢ Simplicidad de Streamlit: Desarrollo Ã¡gil

================================================================================
                                    VIDEO EXPLICATIVO
================================================================================

ğŸ¥ GUION PARA VIDEO EXPLICATIVO (15-16 minutos)

================================================================================
INTRODUCCIÃ“N (0:00 - 1:00)
================================================================================

"Bienvenidos a la presentaciÃ³n del proyecto Fintech Analytics. 
Hoy les mostrarÃ© cÃ³mo desarrollamos un sistema completo de anÃ¡lisis 
de onboarding y A/B testing para una plataforma fintech.

El objetivo era reducir la pÃ©rdida de usuarios durante el proceso 
de onboarding y crear un dashboard en tiempo real para monitorear 
las mÃ©tricas clave del negocio.

Este proyecto demuestra las capacidades de la ingenierÃ­a de datos 
para resolver problemas reales de negocio utilizando tecnologÃ­as 
de Big Data modernas."

================================================================================
CONTEXTO DEL NEGOCIO (1:00 - 2:30)
================================================================================

"El problema que identificamos fue la pÃ©rdida significativa de 
usuarios durante el proceso de onboarding. La empresa necesitaba:

1. Visibilidad en tiempo real del comportamiento de usuarios
2. AnÃ¡lisis del funnel de activaciÃ³n
3. ImplementaciÃ³n de A/B testing para validar mejoras
4. OptimizaciÃ³n de la experiencia del usuario

Para esto definimos 4 mÃ©tricas clave que nos permitirÃ­an medir 
el Ã©xito del proceso de onboarding:

- Drop Rate: Usuarios que abandonan el proceso
- Activation Rate: Usuarios que completan la activaciÃ³n
- Setup Rate: Usuarios que configuran su cuenta
- Habit Rate: Usuarios que desarrollan hÃ¡bito de uso

Estas mÃ©tricas nos darÃ­an una visiÃ³n completa del funnel de 
onboarding y nos permitirÃ­an identificar puntos de fricciÃ³n."

================================================================================
ARQUITECTURA DE LA SOLUCIÃ“N (2:30 - 4:00)
================================================================================

"La arquitectura que diseÃ±amos utiliza tecnologÃ­as de Big Data 
modernas. Les muestro el flujo completo:

Los datos comienzan en archivos CSV con informaciÃ³n de onboarding, 
usuarios y transacciones. Estos datos se procesan con Apache Spark 
usando PySpark, donde realizamos la limpieza, transformaciÃ³n y 
cÃ¡lculo de mÃ©tricas.

Los resultados se almacenan en Apache Cassandra, una base de datos 
NoSQL optimizada para consultas rÃ¡pidas y tiempo real.

Finalmente, un dashboard desarrollado con Streamlit consume los 
datos directamente desde Cassandra, proporcionando visualizaciones 
interactivas y anÃ¡lisis en tiempo real.

Esta arquitectura nos permite:
- Procesar grandes volÃºmenes de datos eficientemente
- Almacenar datos optimizados para consultas rÃ¡pidas
- Visualizar resultados en tiempo real
- Escalar segÃºn las necesidades del negocio"

================================================================================
TECNOLOGÃAS UTILIZADAS (4:00 - 5:30)
================================================================================

"Para el procesamiento de datos elegimos Apache Spark 3.5.0 por 
su capacidad de procesamiento distribuido y escalabilidad. 
PySpark nos permite desarrollar en Python, facilitando el 
desarrollo y mantenimiento.

Para la base de datos seleccionamos Apache Cassandra por su 
optimizaciÃ³n para lecturas rÃ¡pidas y alta disponibilidad. 
El Cassandra Driver nos permite conectar desde Python.

Para el dashboard utilizamos Streamlit, que nos permite crear 
interfaces web interactivas rÃ¡pidamente. Plotly proporciona 
visualizaciones avanzadas y responsivas.

Todo se ejecuta en contenedores Docker para facilitar el 
despliegue y mantenimiento.

Esta combinaciÃ³n de tecnologÃ­as nos da:
- Procesamiento distribuido eficiente
- Almacenamiento optimizado para tiempo real
- Desarrollo rÃ¡pido de interfaces
- Despliegue y mantenimiento simplificado"

================================================================================
PROCESO DE DESARROLLO (5:30 - 7:00)
================================================================================

"El desarrollo se dividiÃ³ en 4 fases principales:

En la Fase 1 realizamos anÃ¡lisis exploratorio de los datos, 
identificando inconsistencias y validando la calidad de los 
datos. Documentamos todos los hallazgos para guiar el desarrollo.

En la Fase 2 diseÃ±amos la arquitectura completa, seleccionando 
las tecnologÃ­as y definiendo las mÃ©tricas de negocio. 
Planificamos el A/B testing con distribuciÃ³n 5% control, 
95% tratamiento.

En la Fase 3 desarrollamos el pipeline ETL con PySpark, 
implementando la limpieza de datos, cÃ¡lculo de mÃ©tricas y 
integraciÃ³n con Cassandra.

En la Fase 4 creamos el dashboard con Streamlit, conectÃ¡ndolo 
directamente a Cassandra para datos en tiempo real.

Cada fase fue iterativa, permitiÃ©ndonos validar y mejorar 
continuamente la soluciÃ³n."

================================================================================
PRE-PROCESAMIENTO Y TRANSFORMACIÃ“N (7:00 - 8:30)
================================================================================

"En el pre-procesamiento implementamos filtros importantes:

Filtramos usuarios sin segmento vÃ¡lido, manteniendo solo 
segmento 1 (Individuals) y 2 (Sellers). Esto mejora la 
calidad del anÃ¡lisis.

Resolvimos inconsistencias de segmentos duplicados, 
tomando el segmento mÃ¡s frecuente por usuario.

Calculamos las mÃ©tricas de negocio:
- Drop Rate: usuarios que no vuelven despuÃ©s del primer login
- Activation Rate: usuarios que completan la activaciÃ³n
- Setup Rate: usuarios que configuran su cuenta
- Habit Rate: diferenciado por segmento

Para Individuals: 5 dÃ­as distintos de transacciones en 30 dÃ­as
Para Sellers: 5 cobros (tipos 8 o 9) en 30 dÃ­as

Implementamos A/B testing con asignaciÃ³n aleatoria para 
simular experimentos futuros.

Esta transformaciÃ³n nos permite tener datos limpios y 
mÃ©tricas consistentes para el anÃ¡lisis."

================================================================================
DECISIONES TÃ‰CNICAS (8:30 - 10:00)
================================================================================

"Las decisiones tÃ©cnicas fueron fundamentales para el Ã©xito:

Elegimos Spark por su capacidad de procesamiento distribuido 
y optimizaciÃ³n de memoria. La integraciÃ³n nativa con Cassandra 
facilita el flujo de datos.

Cassandra fue seleccionada por su optimizaciÃ³n para lecturas 
rÃ¡pidas y escalabilidad horizontal. Su alta disponibilidad 
garantiza que el dashboard siempre tenga datos disponibles.

Streamlit nos permitiÃ³ desarrollar el dashboard rÃ¡pidamente 
con una interfaz intuitiva. La integraciÃ³n con Python facilita 
el mantenimiento.

En la arquitectura de datos usamos LEFT JOINs para mantener 
todos los usuarios de onboarding, implementamos cache inteligente 
de 5 minutos y robusto manejo de errores.

Estas decisiones nos permiten:
- Procesar datos eficientemente
- Almacenar para consultas rÃ¡pidas
- Desarrollar interfaces rÃ¡pidamente
- Mantener alta disponibilidad"

================================================================================
DEMOSTRACIÃ“N DEL PIPELINE (10:00 - 12:00)
================================================================================

"Ahora les muestro el funcionamiento del pipeline:

[DEMOSTRACIÃ“N EN VIVO]

1. Ejecutamos el ETL: python3 etl_pipeline_clean.py
   - Carga de datasets CSV
   - Filtrado de usuarios sin segmento
   - CÃ¡lculo de mÃ©tricas
   - Almacenamiento en Cassandra

2. Ejecutamos el dashboard: streamlit run dashboard_cassandra.py
   - ConexiÃ³n a Cassandra
   - Carga de datos en tiempo real
   - VisualizaciÃ³n del funnel
   - AnÃ¡lisis por segmento
   - ComparaciÃ³n A/B testing

Como pueden ver, el dashboard muestra:
- Funnel de onboarding completo
- MÃ©tricas por segmento (Individuals vs Sellers)
- AnÃ¡lisis A/B testing con diferencias
- Datos raw filtrables y exportables

El sistema es completamente funcional y estÃ¡ listo para 
producciÃ³n."

================================================================================
RESULTADOS Y MÃ‰TRICAS (12:00 - 13:30)
================================================================================

"Los resultados obtenidos muestran un funnel de onboarding 
claro y medible:

En el registro tenemos 100% de usuarios que inician el proceso.
En activaciÃ³n vemos tasas del 60-80%, dependiendo del segmento.
En setup las tasas bajan a 40-60%.
En hÃ¡bito alcanzamos 20-40% de retenciÃ³n.

El anÃ¡lisis por segmento revela diferencias significativas:
- Individuals tienen mejor activaciÃ³n
- Sellers muestran mejor hÃ¡bito de uso

El A/B testing estÃ¡ configurado para validar mejoras futuras, 
con distribuciÃ³n 5% control, 95% tratamiento.

El dashboard proporciona visibilidad completa en tiempo real, 
con configuraciÃ³n dinÃ¡mica y exportaciÃ³n de datos.

Estas mÃ©tricas nos permiten:
- Identificar puntos de fricciÃ³n
- Comparar segmentos de usuarios
- Validar mejoras con A/B testing
- Monitorear en tiempo real"

================================================================================
CONCLUSIONES (13:30 - 15:00)
================================================================================

"En conclusiÃ³n, hemos logrado desarrollar un sistema completo 
de anÃ¡lisis de onboarding que incluye:

âœ… Pipeline ETL automatizado con Spark
âœ… Dashboard en tiempo real con Cassandra
âœ… A/B testing implementado
âœ… MÃ©tricas de negocio claras
âœ… Arquitectura escalable

Los beneficios esperados para el negocio incluyen:
- ReducciÃ³n del drop rate en 10-20%
- Incremento en activation rate de 15-25%
- Mejora en habit formation de 20-30%
- Visibilidad completa del proceso

Los prÃ³ximos pasos incluyen:
1. ImplementaciÃ³n en producciÃ³n
2. Monitoreo continuo de mÃ©tricas
3. OptimizaciÃ³n basada en datos
4. ExpansiÃ³n a otros paÃ­ses
5. ImplementaciÃ³n de Machine Learning

Este proyecto demuestra las capacidades de la ingenierÃ­a de 
datos para resolver problemas reales de negocio utilizando 
tecnologÃ­as de Big Data modernas.

El sistema estÃ¡ listo para producciÃ³n y puede escalar segÃºn 
las necesidades de la empresa."

================================================================================
CIERRE (15:00 - 15:30)
================================================================================

"Gracias por su atenciÃ³n. Este proyecto representa un ejemplo 
concreto de cÃ³mo las tecnologÃ­as de Big Data pueden transformar 
la experiencia del usuario y optimizar procesos de negocio.

El sistema estÃ¡ listo para producciÃ³n y puede escalar segÃºn 
las necesidades de la empresa.

Â¿Tienen alguna pregunta sobre la implementaciÃ³n o los resultados?"

================================================================================
CHECKLIST PARA EL VIDEO
================================================================================

PREPARACIÃ“N:
â–¡ Configurar entorno de desarrollo
â–¡ Tener datos de ejemplo cargados
â–¡ Preparar Cassandra ejecutÃ¡ndose
â–¡ Tener el dashboard funcionando

GRABACIÃ“N:
â–¡ IntroducciÃ³n clara del proyecto
â–¡ ExplicaciÃ³n de la arquitectura
â–¡ DemostraciÃ³n del ETL en vivo
â–¡ DemostraciÃ³n del dashboard en vivo
â–¡ Mostrar resultados y mÃ©tricas
â–¡ Conclusiones y prÃ³ximos pasos

POST-PRODUCCIÃ“N:
â–¡ Editar para mantener 15-16 minutos
â–¡ Agregar transiciones entre secciones
â–¡ Incluir capturas de pantalla del cÃ³digo
â–¡ Agregar subtÃ­tulos si es necesario
â–¡ Verificar calidad de audio y video

================================================================================
COMANDOS PARA EJECUTAR EL PROYECTO
================================================================================

1. INSTALAR DEPENDENCIAS:
   pip install -r requirements.txt

2. LEVANTAR CASSANDRA:
   docker-compose up -d

3. EJECUTAR ETL:
   python3 etl_pipeline_clean.py

4. EJECUTAR DASHBOARD:
   streamlit run dashboard_cassandra.py

================================================================================
ESTRUCTURA DEL PROYECTO
================================================================================

tpfinal_bigdata/
â”œâ”€â”€ artifacts/                          # Resultados del ETL
â”‚   â””â”€â”€ user_onboarding_metrics_clean/  # MÃ©tricas limpias
â”œâ”€â”€ etl_pipeline_clean.py              # ETL principal
â”œâ”€â”€ dashboard_cassandra.py              # Dashboard
â”œâ”€â”€ requirements.txt                    # Dependencias
â”œâ”€â”€ docker-compose.yml                 # ConfiguraciÃ³n
â”œâ”€â”€ README.md                          # DocumentaciÃ³n
â”œâ”€â”€ lk_onboarding.csv                  # Dataset onboarding
â”œâ”€â”€ dim_users.csv                      # Dataset usuarios
â””â”€â”€ bt_users_transactions.csv          # Dataset transacciones

================================================================================
FIN DEL DOCUMENTO
================================================================================

Proyecto desarrollado para el curso de Big Data Engineering
AnÃ¡lisis de onboarding y optimizaciÃ³n de experiencia de usuario
TecnologÃ­as: Spark + Cassandra + Streamlit 