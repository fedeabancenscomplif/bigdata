# ğŸš€ Fintech Analytics - ETL Pipeline & Dashboard

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa un pipeline ETL completo para analizar el onboarding de usuarios en una plataforma fintech, incluyendo un experimento de A/B testing para evaluar la efectividad de diferentes estrategias de activaciÃ³n de usuarios. **El dashboard consume datos directamente desde Cassandra en tiempo real.**

## ğŸ¯ Objetivo

Analizar el comportamiento de los usuarios durante el proceso de onboarding para identificar puntos de fricciÃ³n y optimizar la experiencia del usuario, reduciendo la tasa de abandono y aumentando la activaciÃ³n y retenciÃ³n.

## ğŸ—ï¸ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Datasets CSV  â”‚    â”‚   Apache Spark  â”‚    â”‚  Apache Cassandraâ”‚
â”‚                 â”‚    â”‚   (PySpark)     â”‚    â”‚                 â”‚
â”‚ â€¢ lk_onboarding â”‚â”€â”€â”€â–¶â”‚   ETL Pipeline  â”‚â”€â”€â”€â–¶â”‚   Base de Datos â”‚
â”‚ â€¢ dim_users     â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ transactions  â”‚    â”‚ â€¢ Limpieza      â”‚    â”‚ â€¢ MÃ©tricas      â”‚
â”‚                 â”‚    â”‚ â€¢ TransformaciÃ³nâ”‚    â”‚ â€¢ A/B Testing   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ â€¢ Carga         â”‚    â”‚ â€¢ Tiempo Real   â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
                                                       â–¼
                                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                              â”‚   Streamlit     â”‚
                                              â”‚   Dashboard     â”‚
                                              â”‚                 â”‚
                                              â”‚ â€¢ VisualizaciÃ³n â”‚
                                              â”‚ â€¢ AnÃ¡lisis      â”‚
                                              â”‚ â€¢ Tiempo Real   â”‚
                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Flujo de Datos:**
1. **Ingesta**: Datasets CSV â†’ Apache Spark
2. **Procesamiento**: ETL con PySpark â†’ TransformaciÃ³n y cÃ¡lculo de mÃ©tricas
3. **Almacenamiento**: Resultados â†’ Apache Cassandra
4. **VisualizaciÃ³n**: Dashboard Streamlit â†’ Consume datos directamente desde Cassandra

## ğŸ“Š Datasets Utilizados

- **`lk_onboarding.csv`**: InformaciÃ³n del proceso de onboarding de usuarios
- **`dim_users.csv`**: Detalles de los usuarios
- **`bt_users_transactions.csv`**: Transacciones de los usuarios

## ğŸ”§ TecnologÃ­as del Sistema

- **ETL**: Apache Spark (PySpark)
- **Base de Datos**: Apache Cassandra
- **Dashboard**: Streamlit
- **VisualizaciÃ³n**: Plotly
- **ConexiÃ³n**: Cassandra Driver para Python

## ğŸ“ˆ LÃ³gicas de Negocio - Indicadores Calculados

### **Filtrado de Datos**
- **Usuarios sin segmento**: Se excluyen del anÃ¡lisis usuarios que no tienen segmento asignado
- **Segmentos vÃ¡lidos**: Solo se consideran segmento 1 (Individuals) y 2 (Sellers)
- **Calidad de datos**: Mejora la precisiÃ³n del anÃ¡lisis al eliminar datos inconsistentes

### 1. **Drop Rate (Tasa de Abandono)**
- **DefiniciÃ³n**: Usuarios que abandonan el proceso de onboarding
- **CÃ¡lculo**: `drop = 1` si `return = 0`, `drop = 0` si `return = 1`
- **InterpretaciÃ³n**: Porcentaje de usuarios que no completan el onboarding

### 2. **ActivaciÃ³n Rate (Tasa de ActivaciÃ³n)**
- **DefiniciÃ³n**: Usuarios que completan el proceso de activaciÃ³n
- **CÃ¡lculo**: `activacion = 1` si existe fecha de `activacion_dt`, `activacion = 0` en caso contrario
- **InterpretaciÃ³n**: Porcentaje de usuarios que se activan despuÃ©s del registro

### 3. **Setup Rate (Tasa de ConfiguraciÃ³n)**
- **DefiniciÃ³n**: Usuarios que completan la configuraciÃ³n inicial
- **CÃ¡lculo**: `setup = 1` si existe fecha de `setup_dt`, `setup = 0` en caso contrario
- **InterpretaciÃ³n**: Porcentaje de usuarios que configuran su cuenta

### 4. **HÃ¡bito Rate (Tasa de HÃ¡bito) - Calculado**
- **DefiniciÃ³n**: Usuarios que desarrollan un hÃ¡bito de uso de la plataforma
- **CÃ¡lculo por Segmento**:
  - **Individuals (Segmento 1)**: Usuario con â‰¥5 dÃ­as distintos de transacciones en los primeros 30 dÃ­as
  - **Sellers (Segmento 2)**: Usuario con â‰¥5 cobros (tipos 8 o 9) en los primeros 30 dÃ­as
- **InterpretaciÃ³n**: Porcentaje de usuarios que adoptan la plataforma como hÃ¡bito

## ğŸ”¬ A/B Testing

### **AsignaciÃ³n de Grupos**
- **MÃ©todo**: AsignaciÃ³n aleatoria uniforme
- **DistribuciÃ³n**: 5% Control, 95% Tratamiento
- **PropÃ³sito**: Simular el flujo real de usuarios cuando el experimento estÃ© en producciÃ³n
- **Ventajas**:
  - Elimina sesgos de selecciÃ³n
  - Permite comparaciÃ³n estadÃ­sticamente vÃ¡lida
  - Replica condiciones reales de experimentaciÃ³n

### **Grupos del Experimento**
- **Control**: Grupo que recibe la experiencia actual (baseline)
- **Treatment**: Grupo que recibe la nueva experiencia/feature a testear

## ğŸ—ï¸ Estructura del Proyecto

```
tpfinal_bigdata/
â”œâ”€â”€ artifacts/                          # Resultados del ETL
â”‚   â””â”€â”€ user_onboarding_metrics_clean/  # MÃ©tricas limpias (solo hÃ¡bito calculado)
â”œâ”€â”€ etl_pipeline_clean.py              # ETL principal (versiÃ³n limpia)
â”œâ”€â”€ dashboard_cassandra.py              # Dashboard avanzado (Cassandra)
â”œâ”€â”€ requirements.txt                    # Dependencias
â”œâ”€â”€ docker-compose.yml                 # ConfiguraciÃ³n de servicios
â”œâ”€â”€ README.md                          # DocumentaciÃ³n
â”œâ”€â”€ lk_onboarding.csv                  # Dataset de onboarding
â”œâ”€â”€ dim_users.csv                      # Dataset de usuarios
â””â”€â”€ bt_users_transactions.csv          # Dataset de transacciones
```

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### 1. **Requisitos Previos**
- Python 3.8+
- Java 8+ (para Spark)
- Docker y Docker Compose

### 2. **InstalaciÃ³n de Dependencias**
```bash
pip install -r requirements.txt
```

**Dependencias incluidas:**
- `pyspark==3.5.0` - Procesamiento distribuido
- `cassandra-driver==3.28.0` - Conector para Cassandra
- `streamlit==1.28.1` - Framework de dashboard
- `plotly==5.17.0` - Visualizaciones interactivas
- `pandas==2.1.4` - ManipulaciÃ³n de datos
- `numpy==1.24.3` - CÃ¡lculos numÃ©ricos
- `matplotlib==3.8.2` - Visualizaciones bÃ¡sicas
- `seaborn==0.13.0` - Visualizaciones estadÃ­sticas

### 3. **ConfiguraciÃ³n de Servicios**
```bash
docker-compose up -d
```

## ğŸ“Š EjecuciÃ³n del Pipeline

### 1. **Ejecutar ETL**
```bash
python3 etl_pipeline_clean.py
```

**El ETL realiza:**
- âœ… Carga de datasets CSV
- âœ… Limpieza y validaciÃ³n de datos
- âœ… CÃ¡lculo de mÃ©tricas de negocio
- âœ… AsignaciÃ³n aleatoria de grupos A/B testing
- âœ… Almacenamiento en Cassandra
- âœ… GeneraciÃ³n de archivos CSV de respaldo

### 2. **Ejecutar Dashboard**

```bash
streamlit run dashboard_cassandra.py
```

**CaracterÃ­sticas del Dashboard:**
- âœ… **Datos en tiempo real** desde Cassandra
- âœ… **ConfiguraciÃ³n dinÃ¡mica** de conexiÃ³n (host, puerto, keyspace, tabla)
- âœ… **Prueba de conexiÃ³n** antes de cargar datos
- âœ… **Cache inteligente** (5 minutos) para mejor rendimiento
- âœ… **Barra de progreso** durante la carga de datos
- âœ… **NavegaciÃ³n modular** por secciones
- âœ… **EstadÃ­sticas en tiempo real** de la base de datos
- âœ… **Filtros avanzados** por grupo A/B, segmento y mÃ©tricas
- âœ… **ExportaciÃ³n de datos** filtrados a CSV
- âœ… **Monitoreo de conexiÃ³n** y estadÃ­sticas

**Secciones del Dashboard:**
1. **ğŸ“ˆ Dashboard Completo** - Vista general de todas las mÃ©tricas
2. **ğŸ”„ Funnel** - AnÃ¡lisis del funnel de onboarding
3. **ğŸ‘¥ Segmentos** - ComparaciÃ³n entre Individuals y Sellers
4. **ğŸ”¬ A/B Testing** - AnÃ¡lisis del experimento
5. **ğŸ“Š Datos Raw** - Datos filtrables y exportables

## ğŸ“ˆ MÃ©tricas y KPIs

### **Funnel de Onboarding**
1. **Registro**: 100% (usuarios que inician el proceso)
2. **ActivaciÃ³n**: % de usuarios que completan la activaciÃ³n
3. **Setup**: % de usuarios que configuran su cuenta
4. **HÃ¡bito**: % de usuarios que desarrollan hÃ¡bito de uso

### **AnÃ¡lisis por Segmento**
- **Individuals**: Usuarios individuales (segmento 1)
- **Sellers**: Vendedores/Comerciantes (segmento 2)

### **AnÃ¡lisis A/B Testing**
- ComparaciÃ³n de mÃ©tricas entre grupos control y tratamiento
- Diferencias estadÃ­sticas en tasas de conversiÃ³n
- AnÃ¡lisis de impacto por segmento

## ğŸ” CaracterÃ­sticas del Dashboard

### **âš™ï¸ ConfiguraciÃ³n de Base de Datos**
- **Host configurable**: Por defecto localhost
- **Puerto configurable**: Por defecto 9042
- **Keyspace configurable**: Por defecto fintech_analytics
- **Tabla configurable**: Por defecto user_onboarding_metrics_clean

### **ğŸ” Prueba de ConexiÃ³n**
- **VerificaciÃ³n automÃ¡tica**: Antes de cargar datos
- **Feedback visual**: Ã‰xito, advertencia o error
- **Conteo de registros**: Muestra cuÃ¡ntos datos estÃ¡n disponibles

### **ğŸ“Š Carga Inteligente**
- **Cache de 5 minutos**: Evita consultas repetidas
- **Barra de progreso**: Muestra el avance de la carga
- **Manejo de errores**: Robustez en la conexiÃ³n
- **EstadÃ­sticas en tiempo real**: MÃ©tricas de la base de datos

### **ğŸ¯ NavegaciÃ³n Modular**
- **Dashboard Completo**: Vista general
- **Funnel**: AnÃ¡lisis del flujo de usuarios
- **Segmentos**: ComparaciÃ³n por tipo de usuario
- **A/B Testing**: AnÃ¡lisis del experimento
- **Datos Raw**: Datos filtrables y exportables

### **ğŸ“ˆ EstadÃ­sticas Detalladas**
- **Total de registros**: Desde Cassandra
- **DistribuciÃ³n por segmento**: Individuals vs Sellers
- **DistribuciÃ³n A/B**: Control vs Treatment
- **Ãšltima actualizaciÃ³n**: Timestamp de la carga
- **Fuente de datos**: Cassandra o CSV

### **ğŸ”§ Filtros Avanzados**
- **Por grupo A/B**: Control o Treatment
- **Por segmento**: Individuals o Sellers
- **Por mÃ©tricas**: Con activaciÃ³n, setup, hÃ¡bito, sin drop
- **ExportaciÃ³n**: Descarga de datos filtrados

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Apache Spark**: Procesamiento distribuido de datos
- **Apache Cassandra**: Base de datos NoSQL para almacenamiento en tiempo real
- **Streamlit**: Framework para dashboards web interactivos
- **Plotly**: LibrerÃ­a de visualizaciÃ³n interactiva
- **Cassandra Driver**: Conector Python para Cassandra
- **Docker**: ContainerizaciÃ³n de servicios

## ğŸ“ Notas TÃ©cnicas

### **Procesamiento de Datos**
- **LEFT JOINs**: Para mantener todos los usuarios de onboarding
- **Filtrado por segmento**: Solo usuarios con segmento vÃ¡lido (1 o 2)
- **CÃ¡lculo de hÃ¡bito**: Basado en transacciones reales
- **ResoluciÃ³n de inconsistencias**: De segmentos
- **Formateo de fechas**: Para anÃ¡lisis temporal

### **Optimizaciones**
- **Cache inteligente**: En Streamlit para mejor rendimiento
- **Agregaciones eficientes**: En Spark
- **Consultas optimizadas**: Para lectura rÃ¡pida en Cassandra
- **Manejo de errores**: Robustez en la conexiÃ³n

### **Ventajas de Cassandra**
- **Consultas rÃ¡pidas**: Optimizado para lecturas
- **Escalabilidad**: Maneja grandes volÃºmenes de datos
- **Disponibilidad**: Alta disponibilidad y tolerancia a fallos
- **Tiempo real**: Datos actualizados instantÃ¡neamente

### **Limitaciones de Cassandra**
- **No GROUP BY**: En columnas que no son PRIMARY KEY
- **Consultas simples**: Para mejor rendimiento
- **EstadÃ­sticas con pandas**: Calculadas despuÃ©s de cargar datos

## ğŸ”§ SoluciÃ³n de Problemas

### **Error de GROUP BY en Cassandra**
```
Error: Group by is currently only supported on the columns of the PRIMARY KEY
```
**SoluciÃ³n**: El dashboard calcula estadÃ­sticas usando pandas despuÃ©s de cargar los datos.

### **ConexiÃ³n a Cassandra**
- Verificar que Docker estÃ© ejecutÃ¡ndose
- Verificar que el puerto 9042 estÃ© disponible
- Usar el botÃ³n "Probar ConexiÃ³n" en el dashboard

### **Datos no disponibles**
- Ejecutar el ETL primero: `python3 etl_pipeline_clean.py`
- Verificar que Cassandra estÃ© ejecutÃ¡ndose
- Verificar la conexiÃ³n con el botÃ³n "Probar ConexiÃ³n"

## ğŸ¤ ContribuciÃ³n

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para detalles.

## ğŸ‘¥ Autores

- **Equipo de Big Data Engineering**
- **Fintech Analytics Project**

---

*Proyecto desarrollado para anÃ¡lisis de onboarding y optimizaciÃ³n de experiencia de usuario en plataformas fintech con datos en tiempo real desde Cassandra.* 